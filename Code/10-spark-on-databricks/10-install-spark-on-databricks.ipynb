{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a92b62f-c86b-4a7a-ab75-d9f617fa1f77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Introduction To RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fc54a12-4165-46fa-a3ed-163efd0c3017",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[216] at readRDDFromInputStream at PythonRDD.scala:439"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create an RDD from a list of numbers\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "numbers_rdd = sc.parallelize(numbers)\n",
    "numbers_rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed0ab892-451a-414c-b9c7-f9de4762eb21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[11] at readRDDFromInputStream at PythonRDD.scala:439\n"
     ]
    }
   ],
   "source": [
    "print(numbers_rdd) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3ebb049-0bfc-4845-8a73-d9369c6ce50b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Apply a transformation: multiply each number by 2\n",
    "doubled_rdd = numbers_rdd.map(lambda x: x * 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f41116a4-96fb-43da-83ff-51aa979ae46e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform an action: collect the results to a list\n",
    "result = doubled_rdd.collect()\n",
    "\n",
    "# Print the result\n",
    "print(result)  # Output: [2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dec3c288-82fc-49ea-9e92-7486a917260a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Spark Lazy Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f3ad62f-3dfa-4c7b-901a-08bd8718d564",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Name</th><th>Age</th></tr></thead><tbody><tr><td>Smith</td><td>44</td></tr><tr><td>Adam</td><td>65</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Smith",
         44
        ],
        [
         "Adam",
         65
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Age",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an RDD\n",
    "rdd = sc.parallelize([\n",
    "    (\"John\", 28),\n",
    "    (\"Smith\", 44),\n",
    "    (\"Adam\", 65),\n",
    "    (\"Henry\", 23)\n",
    "])\n",
    "\n",
    "# Apply a map transformation to create a new RDD with a tuple including the name and a boolean flag\n",
    "# if the person is older than 30\n",
    "mapped_rdd = rdd.map(lambda x: (x[0], x[1], x[1] > 30))\n",
    "\n",
    "# Filter the RDD to include only people older than 30\n",
    "filtered_rdd = mapped_rdd.filter(lambda x: x[2])\n",
    "\n",
    "# Convert the filtered RDD back to a DataFrame\n",
    "df = spark.createDataFrame(filtered_rdd, [\"Name\", \"Age\", \"OlderThan30\"])\n",
    "\n",
    "# Select only the name and age columns\n",
    "final_df = df.select(\"Name\", \"Age\")\n",
    "\n",
    "# # Collect the results which triggers the execution of all transformations\n",
    "results = final_df.collect()\n",
    "display(results)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "10-install-spark-on-databricks",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
